#!/usr/bin/env python3
"""
–¢–µ—Å—Ç OpenRouter API –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø—Ä–æ–±–ª–µ–º
"""
import asyncio
import aiohttp
import os
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_openrouter_api():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç OpenRouter API —Å —Ä–∞–∑–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏"""
    
    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key:
        logger.error("‚ùå OPENROUTER_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        return
    
    logger.info(f"üîë –¢–µ—Å—Ç–∏—Ä—É–µ–º API –∫–ª—é—á: {api_key[:10]}...")
    logger.info(f"üîë –î–ª–∏–Ω–∞ –∫–ª—é—á–∞: {len(api_key)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    models_to_test = [
        "google/gemini-2.5-flash-lite-preview-06-17",
        "google/gemini-pro",
        "anthropic/claude-3.5-sonnet",
        "anthropic/claude-3.7-sonnet", 
        "meta-llama/llama-3.1-8b-instruct",
        "openai/gpt-3.5-turbo"
    ]
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    url = "https://openrouter.ai/api/v1/chat/completions"
    
    for model in models_to_test:
        logger.info(f"ü§ñ –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å: {model}")
        
        data = {
            "model": model,
            "messages": [
                {"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ —Ç–µ—Å—Ç."}
            ],
            "max_tokens": 10,
            "temperature": 0.1
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, headers=headers, json=data) as response:
                    logger.info(f"üìä –°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞: {response.status}")
                    
                    if response.status == 200:
                        result = await response.json()
                        content = result["choices"][0]["message"]["content"]
                        logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {model} —Ä–∞–±–æ—Ç–∞–µ—Ç! –û—Ç–≤–µ—Ç: {content}")
                        return model  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—É—é —Ä–∞–±–æ—á—É—é –º–æ–¥–µ–ª—å
                    elif response.status == 401:
                        logger.error(f"‚ùå –ú–æ–¥–µ–ª—å {model}: –û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ (401)")
                    elif response.status == 400:
                        error_text = await response.text()
                        logger.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model}: –ù–µ–¥–æ—Å—Ç—É–ø–Ω–∞ (400) - {error_text}")
                    elif response.status == 429:
                        logger.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model}: –õ–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ (429)")
                    else:
                        error_text = await response.text()
                        logger.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model}: –û—à–∏–±–∫–∞ {response.status} - {error_text}")
                        
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏ {model}: {e}")
    
    logger.error("‚ùå –ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
    return None

if __name__ == "__main__":
    asyncio.run(test_openrouter_api())
